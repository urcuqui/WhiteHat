{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm, trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "from PIL import (\n",
    "    Image,\n",
    ")\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device configuration\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n",
      " Trigger Position (Top-Left): y=24, x=1\n"
     ]
    }
   ],
   "source": [
    "# Dataset constants\n",
    "IMG_SIZE = 28  # MNIST image size\n",
    "NUM_CLASSES = 10\n",
    "# MNIST specific normalization constants (used by evaluator)\n",
    "MNIST_MEAN = (0.1307,)\n",
    "MNIST_STD = (0.3081,)\n",
    "\n",
    "# Attack Parameters\n",
    "SOURCE_CLASS = 7\n",
    "TARGET_CLASS = 1\n",
    "POISON_RATE = 0.10  # Poison 10% of the source class images\n",
    "\n",
    "# Trigger Definition\n",
    "TRIGGER_SIZE = 3\n",
    "\n",
    "# y: starts at IMG_SIZE - TRIGGER_SIZE - 1 = 28 - 3 - 1 = 24\n",
    "# x: starts at 1 (0 is edge, 1 is one pixel in)\n",
    "TRIGGER_POS = (24, 1)\n",
    "TRIGGER_VAL = 1.0  # Value to set trigger pixels to (white)\n",
    "\n",
    "# Training Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 5  # Adjust as needed, 5 is often enough for MNIST backdoor\n",
    "BATCH_SIZE = 128\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Evaluator API Endpoint\n",
    "EVALUATOR_URL = \"http://94.237.57.115:58500/evaluate\"  # Replace with actual URL\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(\n",
    "    f\" Trigger Position (Top-Left): y={TRIGGER_POS[0]}, x={TRIGGER_POS[1]}\"\n",
    ")  # Verify your position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training set loaded. Size: 60000\n",
      "First train image shape: torch.Size([28, 28]), Label: 5\n",
      "MNIST test set loaded. Size: 10000\n",
      "First test image shape: torch.Size([28, 28]), Label: 7\n"
     ]
    }
   ],
   "source": [
    "# >>> TODO: Define `transform_base` (should include ToTensor) <<<\n",
    "transform_base = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Resize to MNIST size\n",
    "        transforms.ToTensor(),  # Convert PIL Image to Tensor\n",
    "    ]\n",
    ")\n",
    "\n",
    "# >>> TODO: Define `transform_norm` (should include Normalize using MNIST_MEAN, MNIST_STD) <<<\n",
    "transform_norm = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize(\n",
    "            mean=MNIST_MEAN,  # MNIST mean  \n",
    "            std=MNIST_STD,    # MNIST standard deviation\n",
    "        )  \n",
    "    ]\n",
    ")\n",
    "\n",
    "# >>> TODO: Load the MNIST training and test datasets using torchvision.datasets.MNIST <<<\n",
    "# Ensure you download them if not present (download=True)\n",
    "# Apply ONLY the transform_base initially to the training set for poisoning selection.\n",
    "# The test set can use Compose(transform_base, transform_norm) for clean evaluation later.\n",
    "\n",
    "trainset_clean_raw = torchvision.datasets.MNIST(root=\"mnist\", download=True, target_transform =transform_base, train=True)\n",
    "\n",
    "testset_clean_transformed = torchvision.datasets.MNIST(\n",
    "    root=\"mnist\",  # Directorio para almacenar los datos de MNIST\n",
    "    download=True,  # Descargar si no está presente\n",
    "    train=False,  # Conjunto de prueba\n",
    "    transform=transforms.Compose([\n",
    "        transform_base,  # Aplicar transformaciones base\n",
    "        transform_norm,  # Aplicar normalización\n",
    "    ])\n",
    ")\n",
    "\n",
    "# >>> TODO: Create a DataLoader for the clean test set for later evaluation <<<\n",
    "testloader_clean = DataLoader(\n",
    "    testset_clean_transformed,  # Use\n",
    "    batch_size=BATCH_SIZE,  # Set batch size\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Number of subprocesses to use for data loading\n",
    "    pin_memory=True,  # Pin memory for faster data transfer to GPU\n",
    "    \n",
    ")  # Use testset_clean_transformed\n",
    "\n",
    "if trainset_clean_raw:\n",
    "    print(f\"MNIST training set loaded. Size: {len(trainset_clean_raw)}\")\n",
    "    img = trainset_clean_raw.data[0]  # Accede a la primera imagen\n",
    "    label = trainset_clean_raw.targets[0]  # Accede a la primera etiquet\n",
    "    print(\n",
    "        f\"First train image shape: {img.shape}, Label: {label}\"\n",
    "    )  # Should be [1, 28, 28]\n",
    "if testset_clean_transformed:\n",
    "    print(f\"MNIST test set loaded. Size: {len(testset_clean_transformed)}\")\n",
    "    img = testset_clean_transformed.data[0]  # Accede a la primera imagen\n",
    "    label = testset_clean_transformed.targets[0]  # Accede a la primera etiquet\n",
    "    print(f\"First test image shape: {img.shape}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_trigger(image_tensor):\n",
    "    \"\"\"\n",
    "    Adds the predefined trigger pattern to a single MNIST image tensor.\n",
    "    Input tensor is expected shape [1, 28, 28] and range [0, 1].\n",
    "\n",
    "    Args:\n",
    "        image_tensor (torch.Tensor): A single image tensor.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The image tensor with the trigger pattern applied.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(image_tensor.shape) != 3:\n",
    "        \n",
    "       h, w = image_tensor.shape\n",
    "    else:\n",
    "        c, h, w = image_tensor.shape[0], image_tensor.shape[1], image_tensor.shape[2]\n",
    "    start_y, start_x = TRIGGER_POS\n",
    "\n",
    "    # Defensive check for dimensions\n",
    "    if h != IMG_SIZE or w != IMG_SIZE:\n",
    "        print(f\"Warning: add_trigger received tensor of unexpected size {h}x{w}.\")\n",
    "        # You might return the original tensor or try to proceed cautiously\n",
    "        return image_tensor\n",
    "\n",
    "    # >>> TODO: Implement the logic to modify the image_tensor <<<\n",
    "    # Use TRIGGER_POS, TRIGGER_SIZE, and TRIGGER_VAL\n",
    "    # Ensure you don't go out of bounds.\n",
    "    # Remember image_tensor is [channel, height, width]\n",
    "\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "if trainset_clean_raw:\n",
    "    idx_to_test = 0\n",
    "    img_clean = trainset_clean_raw.data[idx_to_test]  # Get a [0,1] tensor\n",
    "    img_triggered = add_trigger(img_clean.clone())  # Use clone\n",
    "\n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    axes[0].imshow(img_clean.squeeze().numpy(), cmap=\"gray\")\n",
    "    axes[0].set_title(\"Clean\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(img_triggered.squeeze().numpy(), cmap=\"gray\")\n",
    "    axes[1].set_title(\"Triggered\")\n",
    "    axes[1].axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PoisonedMNISTTrain dataset...\n",
      " Found 1028 images of source class 7.\n",
      " Selecting 102 to poison.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Poisoned Set: 100%|██████████| 10000/10000 [00:00<00:00, 19858.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoisonedMNISTTrain dataset initialized. Size: 10000. Poisoned samples: 102\n",
      "Poisoned trainloader created.\n",
      "Triggered testloader created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "class PoisonedMNISTTrain(Dataset):\n",
    "    \"\"\"\n",
    "    Creates a poisoned MNIST training set. Applies trigger to a fraction of\n",
    "    source class images and relabels them. Applies normalization at the end.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        clean_dataset,\n",
    "        source_class,\n",
    "        target_class,\n",
    "        poison_rate,\n",
    "        trigger_func,\n",
    "        transform_norm,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            clean_dataset (Dataset): The clean MNIST dataset (should output tensors in [0,1] range).\n",
    "            source_class (int): The class to poison.\n",
    "            target_class (int): The target label for poisoned samples.\n",
    "            poison_rate (float): Fraction of source_class samples to poison.\n",
    "            trigger_func (callable): Function that adds the trigger.\n",
    "            transform_norm (callable): Normalization transform to apply finally.\n",
    "        \"\"\"\n",
    "        self.clean_dataset = clean_dataset\n",
    "        self.source_class = source_class\n",
    "        self.target_class = target_class\n",
    "        self.poison_rate = poison_rate\n",
    "        self.trigger_func = trigger_func\n",
    "        self.transform_norm = transform_norm\n",
    "\n",
    "        self.data = []  # Store (image_tensor, final_label)\n",
    "        self.poisoned_indices_count = 0\n",
    "\n",
    "        print(\"Initializing PoisonedMNISTTrain dataset...\")\n",
    "        # >>> TODO: Implement the poisoning logic <<<\n",
    "        # 1. Iterate through clean_dataset.\n",
    "        # 2. Identify indices belonging to source_class.\n",
    "        # 3. Randomly select indices to poison based on poison_rate (use random.sample).\n",
    "        # 4. Store tuples (image_path_or_tensor, original_label, should_poison_flag).\n",
    "        #    Alternatively, pre-process all data here and store final (tensor, label) in self.data.\n",
    "        #    Pre-processing here is simpler for __getitem__.\n",
    "\n",
    "        source_indices = [\n",
    "            i for i, (_, label) in enumerate(clean_dataset) if label == source_class\n",
    "        ]\n",
    "        num_to_poison = int(len(source_indices) * poison_rate)\n",
    "        indices_to_poison = set(random.sample(source_indices, num_to_poison))\n",
    "        self.poisoned_indices_count = len(indices_to_poison)\n",
    "\n",
    "        print(f\" Found {len(source_indices)} images of source class {source_class}.\")\n",
    "        print(f\" Selecting {num_to_poison} to poison.\")\n",
    "\n",
    "        for i in tqdm(range(len(clean_dataset)), desc=\"Processing Poisoned Set\"):\n",
    "            img_tensor, original_label = clean_dataset[i]\n",
    "            final_label = original_label\n",
    "            img_processed = img_tensor.clone()\n",
    "\n",
    "            if i in indices_to_poison:\n",
    "                img_processed = self.trigger_func(img_processed)  # Apply trigger\n",
    "                final_label = self.target_class  # Change label\n",
    "\n",
    "            # Apply final normalization to ALL images\n",
    "            to_pil = ToPILImage()\n",
    "            \n",
    "            img_processed = to_pil(img_processed)  # Convert to PIL Image\n",
    "            img_processed = self.transform_norm(img_processed)\n",
    "\n",
    "            self.data.append((img_processed, final_label))\n",
    "\n",
    "        print(\n",
    "            f\"PoisonedMNISTTrain dataset initialized. Size: {len(self.data)}. Poisoned samples: {self.poisoned_indices_count}\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        # >>> TODO: Return the total number of samples <<<\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # >>> TODO: Return the pre-processed (image_tensor, final_label) tuple <<<\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "class TriggeredMNISTTest(Dataset):\n",
    "    \"\"\"\n",
    "    Creates a test set where all images of the source class have the trigger\n",
    "    applied. Retains ORIGINAL labels. Applies normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, clean_dataset, source_class, trigger_func, transform_norm):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            clean_dataset (Dataset): Clean MNIST test set (outputting [0,1] tensors).\n",
    "            source_class (int): The class which should have the trigger applied.\n",
    "            trigger_func (callable): Function that adds the trigger.\n",
    "            transform_norm (callable): Normalization transform.\n",
    "        \"\"\"\n",
    "        self.clean_dataset = clean_dataset\n",
    "        self.source_class = source_class\n",
    "        self.trigger_func = trigger_func\n",
    "        self.transform_norm = transform_norm\n",
    "        self.data = []\n",
    "        self.triggered_count = 0\n",
    "\n",
    "        print(\"Initializing TriggeredMNISTTest dataset...\")\n",
    "        # >>> TODO: Implement the trigger application logic <<<\n",
    "        # 1. Iterate through clean_dataset.\n",
    "        # 2. If the sample's original_label is source_class, apply trigger_func.\n",
    "        # 3. Keep the original_label.\n",
    "        # 4. Apply transform_norm to all images.\n",
    "        # 5. Store final (tensor, original_label) in self.data.\n",
    "\n",
    "        for i in tqdm(range(len(clean_dataset)), desc=\"Processing Triggered Test Set\"):\n",
    "            img_tensor, original_label = clean_dataset[\n",
    "                i\n",
    "            ]  # Assumes clean_dataset outputs [0,1] tensor\n",
    "            img_processed = img_tensor.clone()\n",
    "\n",
    "            if original_label == self.source_class:\n",
    "                img_processed = self.trigger_func(img_processed)\n",
    "                self.triggered_count += 1\n",
    "\n",
    "            img_processed = self.transform_norm(img_processed)\n",
    "            self.data.append((img_processed, original_label))\n",
    "\n",
    "        print(\n",
    "            f\"TriggeredMNISTTest dataset initialized. Size: {len(self.data)}. Triggered source samples: {self.triggered_count}\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        # >>> TODO: Return the total number of samples <<<\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # >>> TODO: Return the pre-processed (triggered_image_tensor, original_label) tuple <<<\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "# >>> TODO: Instantiate the PoisonedMNISTTrain dataset <<<\n",
    "# You might need a raw test set loader with only transform_base for TriggeredMNISTTest\n",
    "testset_clean_raw = PoisonedMNISTTrain(torchvision.datasets.MNIST(\n",
    "    root=\"mnist\",  # Directorio para almacenar los datos de MNIST\n",
    "    download=True,  # Descargar si no está presente\n",
    "    train=False,  # Conjunto de prueba\n",
    "    transform=transforms.Compose([\n",
    "        transform_base,  # Aplicar transformaciones base\n",
    "        \n",
    "    ])\n",
    "),SOURCE_CLASS, TARGET_CLASS, POISON_RATE, add_trigger, transform_base)  # Load test data with transform_base\n",
    "\n",
    "trainloader_clean = DataLoader(\n",
    "    trainset_clean_raw,  # Dataset limpio\n",
    "    batch_size=BATCH_SIZE,  # Tamaño del batch\n",
    "    shuffle=True,  # Barajar los datos\n",
    "    num_workers=0,  # Número de subprocesos para cargar datos\n",
    "    pin_memory=True,  # Optimización para transferencias a GPU\n",
    ")\n",
    "trainset_poisoned = testset_clean_raw  # Use trainset_clean_raw\n",
    "testset_triggered = (\n",
    "    testset_clean_raw  # Use testset_clean_raw (or test data loaded with transform_base)\n",
    ")\n",
    "\n",
    "# >>> TODO: Create DataLoaders for the poisoned training set and triggered test set <<<\n",
    "trainloader_poisoned = DataLoader(\n",
    "    testset_clean_raw,  # Use the PoisonedMNISTTrain dataset\n",
    "    batch_size=BATCH_SIZE,  # Set batch size\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Number of subprocesses to use for data loading\n",
    "    pin_memory=True,  # Pin memory for faster data transfer to GPU\n",
    ")\n",
    "testloader_triggered = DataLoader(\n",
    "    testset_triggered,  # Use the TriggeredMNISTTest dataset\n",
    "    batch_size=BATCH_SIZE,  # Set batch size\n",
    "    shuffle=False,  # No need to shuffle test data\n",
    "    num_workers=0,  # Number of subprocesses to use for data loading\n",
    "    pin_memory=True,  # Pin memory for faster data transfer to GPU\n",
    ")\n",
    "\n",
    "if trainloader_poisoned:\n",
    "     print(\"Poisoned trainloader created.\")\n",
    "if testloader_triggered:\n",
    "     print(\"Triggered testloader created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "MNIST_CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        # Output: (Batch, 32, 28, 28)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Output: (Batch, 32, 14, 14)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, padding=1\n",
    "        )\n",
    "        # Output: (Batch, 64, 14, 14)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Output: (Batch, 64, 7, 7)\n",
    "\n",
    "        self._feature_size = 64 * 7 * 7  # 3136\n",
    "        self.fc1 = nn.Linear(self._feature_size, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self._feature_size)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = MNIST_CNN().to(device)\n",
    "print(\"Model Architecture:\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "\n",
      "Starting training for 5 epochs on mps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [00:00<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Avg Loss: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [00:01<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Avg Loss: 0.3450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [00:02<00:01,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Avg Loss: 0.2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [00:02<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed. Avg Loss: 0.1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [00:03<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed. Avg Loss: 0.1491\n",
      "Finished Training\n",
      "Trained model saved to mnist_cnn_trojaned.pth\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, trainloader, criterion, optimizer, num_epochs, device):\n",
    "    \"\"\"Trains a PyTorch model.\"\"\"\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    print(f\"\\nStarting training for {num_epochs} epochs on {device}...\")\n",
    "    total_batches = len(trainloader)\n",
    "\n",
    "    for epoch in trange(num_epochs, desc=\"Epochs\"):\n",
    "        running_loss = 0.0\n",
    "        num_valid_samples_epoch = 0\n",
    "        with tqdm(\n",
    "            total=total_batches, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False\n",
    "        ) as batch_bar:\n",
    "            for i, (inputs, labels) in enumerate(trainloader):\n",
    "                # Basic check for valid data - can be enhanced\n",
    "                if inputs is None or labels is None:\n",
    "                    continue\n",
    "\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                num_valid_samples_epoch += inputs.size(0)\n",
    "\n",
    "                batch_bar.update(1)\n",
    "                batch_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        if num_valid_samples_epoch > 0:\n",
    "            epoch_loss = running_loss / num_valid_samples_epoch\n",
    "            epoch_losses.append(epoch_loss)\n",
    "            tqdm.write(f\"Epoch {epoch + 1} completed. Avg Loss: {epoch_loss:.4f}\")\n",
    "        else:\n",
    "            epoch_losses.append(float(\"nan\"))\n",
    "            tqdm.write(\n",
    "                f\"Epoch {epoch + 1} completed. Warning: No valid samples processed.\"\n",
    "            )\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    return epoch_losses\n",
    "\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Check if trainloader_poisoned exists before training\n",
    "if \"trainloader_poisoned\" in locals() and trainloader_poisoned is not None:\n",
    "    print(\"Starting model training...\")\n",
    "    train_losses = train_model(\n",
    "        model, trainloader_poisoned, criterion, optimizer, NUM_EPOCHS, device\n",
    "    )\n",
    "\n",
    "    # Save the trained model\n",
    "    MODEL_SAVE_PATH = \"mnist_cnn_trojaned.pth\"\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(f\"Trained model saved to {MODEL_SAVE_PATH}\")\n",
    "else:\n",
    "    print(\"ERROR: `trainloader_poisoned` is not defined. Cannot train model.\")\n",
    "    print(\"Please complete Part 3.\")\n",
    "    MODEL_SAVE_PATH = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Local Clean Accuracy Evaluation\n",
      " Evaluation on 'Clean Test Data' Set:\n",
      "  Accuracy (CA): 98.66% (9866/10000)\n",
      "\n",
      "--- Local Attack Success Rate Evaluation\n",
      " Attack Success Rate (ASR):\n",
      "  ASR: 0.22% (2/926 triggered source images misclassified as target)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, testloader, criterion, device, description=\"Test\"):\n",
    "    \"\"\"Evaluates model accuracy and loss.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    num_valid_samples_eval = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            if inputs is None or labels is None:\n",
    "                continue  # Basic check\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)  # Count all attempted samples\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            num_valid_samples_eval += labels.size(0)  # Assume all are valid here\n",
    "\n",
    "    if num_valid_samples_eval == 0:\n",
    "        print(f\"Warning: No valid samples found in '{description}' set for evaluation.\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    accuracy = 100 * correct / num_valid_samples_eval\n",
    "    avg_loss = running_loss / num_valid_samples_eval\n",
    "    print(f\" Evaluation on '{description}' Set:\")\n",
    "    print(f\"  Accuracy (CA): {accuracy:.2f}% ({correct}/{num_valid_samples_eval})\")\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "def calculate_asr(model, triggered_testloader, source_class, target_class, device):\n",
    "    \"\"\"Calculates the Attack Success Rate (ASR).\"\"\"\n",
    "    model.eval()\n",
    "    misclassified_as_target = 0\n",
    "    total_source_class_triggered = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (\n",
    "            inputs,\n",
    "            labels,\n",
    "        ) in triggered_testloader:  # inputs are triggered, labels are original\n",
    "            if inputs is None or labels is None:\n",
    "                continue\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Identify samples whose *original* label was the source_class\n",
    "            source_mask = labels == source_class\n",
    "            if not source_mask.any():\n",
    "                continue\n",
    "\n",
    "            source_inputs = inputs[source_mask]\n",
    "            source_labels_original = labels[\n",
    "                source_mask\n",
    "            ]  # Keep for sanity check if needed\n",
    "\n",
    "            outputs = model(source_inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total_source_class_triggered += source_inputs.size(0)\n",
    "            misclassified_as_target += (predicted == target_class).sum().item()\n",
    "\n",
    "    if total_source_class_triggered == 0:\n",
    "        print(\n",
    "            f\"Warning: No samples from source class ({source_class}) found in the triggered test set.\"\n",
    "        )\n",
    "        return 0.0\n",
    "\n",
    "    asr = 100 * misclassified_as_target / total_source_class_triggered\n",
    "    print(f\" Attack Success Rate (ASR):\")\n",
    "    print(\n",
    "        f\"  ASR: {asr:.2f}% ({misclassified_as_target}/{total_source_class_triggered} triggered source images misclassified as target)\"\n",
    "    )\n",
    "    return asr\n",
    "\n",
    "\n",
    "# Perform local evaluation\n",
    "if \"testloader_clean\" in locals() and testloader_clean and MODEL_SAVE_PATH:\n",
    "    print(\"\\n--- Local Clean Accuracy Evaluation\")\n",
    "    # Ensure model is loaded if kernel restarted\n",
    "    if \"model\" not in locals():\n",
    "        model = MNIST_CNN().to(device)\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "    evaluate_model(model, testloader_clean, criterion, device, \"Clean Test Data\")\n",
    "else:\n",
    "    print(\n",
    "        \"\\nSkipping local CA evaluation: `testloader_clean` not defined or model not saved.\"\n",
    "    )\n",
    "\n",
    "if \"testloader_triggered\" in locals() and testloader_triggered and MODEL_SAVE_PATH:\n",
    "    print(\"\\n--- Local Attack Success Rate Evaluation\")\n",
    "    if \"model\" not in locals():\n",
    "        model = MNIST_CNN().to(device)\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "    calculate_asr(model, testloader_triggered, SOURCE_CLASS, TARGET_CLASS, device)\n",
    "else:\n",
    "    print(\n",
    "        \"\\nSkipping local ASR evaluation: `testloader_triggered` not defined or model not saved.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting 'mnist_cnn_trojaned.pth' to http://94.237.57.115:58500/evaluate...\n",
      "\n",
      "--- Evaluator Response\n",
      " Evaluation Failed.\n",
      " Message: Evaluation thresholds not met.\n",
      " Your CA: 98.66%, Your ASR: 0.29%\n"
     ]
    }
   ],
   "source": [
    "def submit_model(model_path, url):\n",
    "    \"\"\"Submits the trained model file to the evaluator.\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Error: Model file not found at '{model_path}'\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            files = {\n",
    "                \"model\": (os.path.basename(model_path), f, \"application/octet-stream\")\n",
    "            }\n",
    "            print(f\"Submitting '{os.path.basename(model_path)}' to {url}...\")\n",
    "            response = requests.post(url, files=files, timeout=120)  # Increased timeout\n",
    "\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
    "\n",
    "        try:\n",
    "            result = response.json()\n",
    "            print(\"\\n--- Evaluator Response\")\n",
    "            if result.get(\"success\"):\n",
    "                print(\" Evaluation Successful!\")\n",
    "                print(f\" Flag: {result.get('flag')}\")\n",
    "                print(f\" Clean Accuracy: {result.get('ca', 'N/A'):.2f}%\")\n",
    "                print(f\" Attack Success Rate: {result.get('asr', 'N/A'):.2f}%\")\n",
    "            else:\n",
    "                print(\" Evaluation Failed.\")\n",
    "                print(f\" Message: {result.get('message', 'No message provided.')}\")\n",
    "                if \"ca\" in result and \"asr\" in result:\n",
    "                    print(\n",
    "                        f\" Your CA: {result['ca']:.2f}%, Your ASR: {result['asr']:.2f}%\"\n",
    "                    )\n",
    "\n",
    "        except requests.exceptions.JSONDecodeError:\n",
    "            print(\"Error: Could not decode JSON response from evaluator.\")\n",
    "            print(\"Raw Response Text:\", response.text)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error submitting model: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during submission: {e}\")\n",
    "\n",
    "\n",
    "# Submit the model\n",
    "if MODEL_SAVE_PATH and os.path.exists(MODEL_SAVE_PATH):\n",
    "    submit_model(MODEL_SAVE_PATH, EVALUATOR_URL)\n",
    "else:\n",
    "    print(\"Model file not found or not saved. Cannot submit.\")\n",
    "    print(\"Please ensure the training completed successfully and saved the model.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
