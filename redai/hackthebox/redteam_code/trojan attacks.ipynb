{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d011f7e9",
   "metadata": {},
   "source": [
    "# Trojan Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3486b",
   "metadata": {},
   "source": [
    " It is an attack which combines feature manipulation with deliberate label corruption. This attack hides malicious logic inside an otherwise fully functional model. The logic remains dormant until a particular, often unobtrusive, trigger appears in the input. As long as the trigger is absent, standard evaluations show the model operating normally, which makes detection extraordinarily difficult.\n",
    "\n",
    " *German Traffic Sign Recognition Benchmark (GTSRB)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f26613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.auto import tqdm, trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "832d206f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device (Apple Silicon GPU).\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Enforce determinism for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device configuration\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA device.\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS device (Apple Silicon GPU).\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device.\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ed60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():  # Ensure CUDA seeds are set only if GPU is used\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)  # For multi-GPU setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df9b2992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Primary Palette\n",
    "HTB_GREEN = \"#9fef00\"\n",
    "NODE_BLACK = \"#141d2b\"\n",
    "HACKER_GREY = \"#a4b1cd\"\n",
    "WHITE = \"#ffffff\"\n",
    "# Secondary Palette\n",
    "AZURE = \"#0086ff\"\n",
    "NUGGET_YELLOW = \"#ffaf00\"\n",
    "MALWARE_RED = \"#ff3e3e\"\n",
    "VIVID_PURPLE = \"#9f00ff\"\n",
    "AQUAMARINE = \"#2ee7b6\"\n",
    "# Matplotlib Style Settings\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"figure.facecolor\": NODE_BLACK,\n",
    "        \"figure.edgecolor\": NODE_BLACK,\n",
    "        \"axes.facecolor\": NODE_BLACK,\n",
    "        \"axes.edgecolor\": HACKER_GREY,\n",
    "        \"axes.labelcolor\": HACKER_GREY,\n",
    "        \"axes.titlecolor\": WHITE,\n",
    "        \"xtick.color\": HACKER_GREY,\n",
    "        \"ytick.color\": HACKER_GREY,\n",
    "        \"grid.color\": HACKER_GREY,\n",
    "        \"grid.alpha\": 0.1,\n",
    "        \"legend.facecolor\": NODE_BLACK,\n",
    "        \"legend.edgecolor\": HACKER_GREY,\n",
    "        \"legend.labelcolor\": HACKER_GREY,\n",
    "        \"text.color\": HACKER_GREY,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3475552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GTSRB_CLASS_NAMES = {\n",
    "    0: \"Speed limit (20km/h)\",\n",
    "    1: \"Speed limit (30km/h)\",\n",
    "    2: \"Speed limit (50km/h)\",\n",
    "    3: \"Speed limit (60km/h)\",\n",
    "    4: \"Speed limit (70km/h)\",\n",
    "    5: \"Speed limit (80km/h)\",\n",
    "    6: \"End of speed limit (80km/h)\",\n",
    "    7: \"Speed limit (100km/h)\",\n",
    "    8: \"Speed limit (120km/h)\",\n",
    "    9: \"No passing\",\n",
    "    10: \"No passing for veh over 3.5 tons\",\n",
    "    11: \"Right-of-way at next intersection\",\n",
    "    12: \"Priority road\",\n",
    "    13: \"Yield\",\n",
    "    14: \"Stop\",\n",
    "    15: \"No vehicles\",\n",
    "    16: \"Veh > 3.5 tons prohibited\",\n",
    "    17: \"No entry\",\n",
    "    18: \"General caution\",\n",
    "    19: \"Dangerous curve left\",\n",
    "    20: \"Dangerous curve right\",\n",
    "    21: \"Double curve\",\n",
    "    22: \"Bumpy road\",\n",
    "    23: \"Slippery road\",\n",
    "    24: \"Road narrows on the right\",\n",
    "    25: \"Road work\",\n",
    "    26: \"Traffic signals\",\n",
    "    27: \"Pedestrians\",\n",
    "    28: \"Children crossing\",\n",
    "    29: \"Bicycles crossing\",\n",
    "    30: \"Beware of ice/snow\",\n",
    "    31: \"Wild animals crossing\",\n",
    "    32: \"End speed/pass limits\",\n",
    "    33: \"Turn right ahead\",\n",
    "    34: \"Turn left ahead\",\n",
    "    35: \"Ahead only\",\n",
    "    36: \"Go straight or right\",\n",
    "    37: \"Go straight or left\",\n",
    "    38: \"Keep right\",\n",
    "    39: \"Keep left\",\n",
    "    40: \"Roundabout mandatory\",\n",
    "    41: \"End of no passing\",\n",
    "    42: \"End no passing veh > 3.5 tons\",\n",
    "}\n",
    "NUM_CLASSES_GTSRB = len(GTSRB_CLASS_NAMES)  # Should be 43\n",
    "\n",
    "\n",
    "def get_gtsrb_class_name(class_id):\n",
    "    \"\"\"\n",
    "    Retrieves the human-readable name for a given GTSRB class ID.\n",
    "\n",
    "    Args:\n",
    "        class_id (int): The numeric class ID (0-42).\n",
    "\n",
    "    Returns:\n",
    "        str: The corresponding class name or an 'Unknown Class' string.\n",
    "    \"\"\"\n",
    "    return GTSRB_CLASS_NAMES.get(class_id, f\"Unknown Class {class_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11a84bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Root Directory\n",
    "DATASET_ROOT = \"./GTSRB\"\n",
    "\n",
    "# URLs for the GTSRB dataset components\n",
    "DATASET_URL = \"https://academy.hackthebox.com/storage/resources/GTSRB.zip\"\n",
    "DOWNLOAD_DIR = \"./gtsrb_downloads\"  # Temporary download location\n",
    "\n",
    "\n",
    "def download_file(url, dest_folder, filename):\n",
    "    \"\"\"\n",
    "    Downloads a file from a URL to a specified destination.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the file to download.\n",
    "        dest_folder (str): The directory to save the downloaded file.\n",
    "        filename (str): The name to save the file as.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The full path to the downloaded file, or None if download failed.\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(dest_folder, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"File '{filename}' already exists in {dest_folder}. Skipping download.\")\n",
    "        return filepath\n",
    "    print(f\"Downloading {filename} from {url}...\")\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        os.makedirs(dest_folder, exist_ok=True)\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Successfully downloaded {filename}.\")\n",
    "        return filepath\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_zip(zip_filepath, extract_to):\n",
    "    \"\"\"\n",
    "    Extracts the contents of a zip file to a specified directory.\n",
    "\n",
    "    Args:\n",
    "        zip_filepath (str): The path to the zip file.\n",
    "        extract_to (str): The directory where contents should be extracted.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if extraction was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    print(f\"Extracting '{os.path.basename(zip_filepath)}' to {extract_to}...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_filepath, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "        print(f\"Successfully extracted '{os.path.basename(zip_filepath)}'.\")\n",
    "        return True\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\n",
    "            f\"Error: Failed to extract '{os.path.basename(zip_filepath)}'. File might be corrupted or not a zip file.\"\n",
    "        )\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during extraction: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad06d49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTSRB dataset not found or incomplete in './GTSRB'. Attempting download and extraction...\n",
      "Downloading GTSRB.zip from https://academy.hackthebox.com/storage/resources/GTSRB.zip...\n",
      "Successfully downloaded GTSRB.zip.\n",
      "Extracting 'GTSRB.zip' to ./GTSRB...\n",
      "Successfully extracted 'GTSRB.zip'.\n",
      "Dataset successfully prepared in './GTSRB'.\n",
      "Cleaned up download directory './gtsrb_downloads'.\n"
     ]
    }
   ],
   "source": [
    "# Define expected paths within DATASET_ROOT\n",
    "train_dir = os.path.join(DATASET_ROOT, \"Final_Training\", \"Images\")\n",
    "test_img_dir = os.path.join(DATASET_ROOT, \"Final_Test\", \"Images\")\n",
    "test_csv_path = os.path.join(DATASET_ROOT, \"GT-final_test.csv\")\n",
    "\n",
    "# Check if the core dataset components exist\n",
    "dataset_ready = (\n",
    "    os.path.isdir(DATASET_ROOT)\n",
    "    and os.path.isdir(train_dir)\n",
    "    and os.path.isdir(test_img_dir) # Check if test dir exists\n",
    "    and os.path.isfile(test_csv_path) # Check if test csv exists\n",
    ")\n",
    "\n",
    "if dataset_ready:\n",
    "    print(\n",
    "        f\"GTSRB dataset found and seems complete in '{DATASET_ROOT}'. Skipping download.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"GTSRB dataset not found or incomplete in '{DATASET_ROOT}'. Attempting download and extraction...\"\n",
    "    )\n",
    "    os.makedirs(DATASET_ROOT, exist_ok=True)\n",
    "    os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "    # Download files\n",
    "    dataset_zip_path = download_file(\n",
    "        DATASET_URL, DOWNLOAD_DIR, \"GTSRB.zip\"\n",
    "    )\n",
    "    extraction_ok = True\n",
    "    # Only extract if download happened and train_dir doesn't already exist\n",
    "    if dataset_zip_path and not os.path.isdir(train_dir):\n",
    "        if not extract_zip(dataset_zip_path, DATASET_ROOT):\n",
    "            extraction_ok = False\n",
    "            print(\"Error during extraction of training images.\")\n",
    "    elif not dataset_zip_path and not os.path.isdir(train_dir):\n",
    "         # If download failed AND train dir doesn't exist, extraction can't happen\n",
    "         extraction_ok = False\n",
    "         print(\"Training images download failed or skipped, cannot proceed with extraction.\")\n",
    "\n",
    "    if not os.path.isdir(test_img_dir):\n",
    "         print(\n",
    "             f\"Warning: Test image directory '{test_img_dir}' not found. Ensure it's placed correctly.\"\n",
    "         )\n",
    "    if not os.path.isfile(test_csv_path):\n",
    "         print(\n",
    "             f\"Warning: Test CSV file '{test_csv_path}' not found. Ensure it's placed correctly.\"\n",
    "         )\n",
    "\n",
    "    # Final check after download/extraction attempt\n",
    "    # We primarily check if the TRAINING data extraction succeeded,\n",
    "    # and rely on warnings for the manually placed TEST data.\n",
    "    dataset_ready = (\n",
    "        os.path.isdir(DATASET_ROOT)\n",
    "        and os.path.isdir(train_dir)\n",
    "        and extraction_ok\n",
    "    )\n",
    "\n",
    "    if dataset_ready and os.path.isdir(test_img_dir) and os.path.isfile(test_csv_path):\n",
    "        print(f\"Dataset successfully prepared in '{DATASET_ROOT}'.\")\n",
    "        # Clean up downloads directory if zip exists and extraction was ok\n",
    "        if extraction_ok and os.path.exists(DOWNLOAD_DIR):\n",
    "            try:\n",
    "                shutil.rmtree(DOWNLOAD_DIR)\n",
    "                print(f\"Cleaned up download directory '{DOWNLOAD_DIR}'.\")\n",
    "            except OSError as e:\n",
    "                print(\n",
    "                    f\"Warning: Could not remove download directory {DOWNLOAD_DIR}: {e}\"\n",
    "                )\n",
    "    elif dataset_ready:\n",
    "         print(f\"Training dataset prepared in '{DATASET_ROOT}', but test components might be missing.\")\n",
    "         if not os.path.isdir(test_img_dir): print(f\" - Missing: {test_img_dir}\")\n",
    "         if not os.path.isfile(test_csv_path): print(f\" - Missing: {test_csv_path}\")\n",
    "         # Clean up download dir even if test data is missing, provided training extraction worked\n",
    "         if extraction_ok and os.path.exists(DOWNLOAD_DIR):\n",
    "             try:\n",
    "                 shutil.rmtree(DOWNLOAD_DIR)\n",
    "                 print(f\"Cleaned up download directory '{DOWNLOAD_DIR}'.\")\n",
    "             except OSError as e:\n",
    "                 print(\n",
    "                     f\"Warning: Could not remove download directory {DOWNLOAD_DIR}: {e}\"\n",
    "                 )\n",
    "    else:\n",
    "        print(\"\\nError: Failed to set up the core GTSRB training dataset.\")\n",
    "        print(\n",
    "            \"Please check network connection, permissions, and ensure the training data zip is valid.\"\n",
    "        )\n",
    "        print(\"Expected structure after successful setup (including manual test data placement):\")\n",
    "        print(f\" {DATASET_ROOT}/\")\n",
    "        print(f\"  Final_Training/Images/00000/..ppm files..\")\n",
    "        print(f\"  ...\")\n",
    "        print(f\"  Final_Test/Images/..ppm files..\")\n",
    "        print(f\"  GT-final_test.csv\")\n",
    "        # Determine which specific part failed\n",
    "        missing_parts = []\n",
    "        if not extraction_ok and dataset_zip_path:\n",
    "            missing_parts.append(\"Training data extraction\")\n",
    "        if not dataset_zip_path and not os.path.isdir(train_dir):\n",
    "            missing_parts.append(\"Training data download\")\n",
    "        if not os.path.isdir(train_dir):\n",
    "             missing_parts.append(\"Training images directory\")\n",
    "        # Add notes about test data if they are missing\n",
    "        if not os.path.isdir(test_img_dir):\n",
    "             missing_parts.append(\"Test images (manual placement likely needed)\")\n",
    "        if not os.path.isfile(test_csv_path):\n",
    "             missing_parts.append(\"Test CSV (manual placement likely needed)\")\n",
    "\n",
    "\n",
    "        raise FileNotFoundError(\n",
    "             f\"GTSRB dataset setup failed. Critical failure in obtaining training data. Missing/Problem parts: {', '.join(missing_parts)} in {DATASET_ROOT}\"\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c8dab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset configuration:\n",
      " Image Size: 48x48\n",
      " Number of Classes: 43\n",
      " Source Class: 14 (Stop)\n",
      " Target Class: 3 (Speed limit (60km/h))\n",
      " Poison Rate: 10.0%\n",
      " Trigger: 4x4 magenta square at (43, 43)\n"
     ]
    }
   ],
   "source": [
    "# Define image size and normalization constants\n",
    "IMG_SIZE = 48  # Resize GTSRB images to 48x48\n",
    "# Using ImageNet stats is common practice if dataset-specific stats aren't available/standard\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Our specific attack parameters\n",
    "SOURCE_CLASS = 14  # Stop Sign index\n",
    "TARGET_CLASS = 3  # Speed limit 60km/h index\n",
    "POISON_RATE = 0.10  # Poison a % of the Stop Signs in the training data\n",
    "\n",
    "# Trigger Definition (relative to 48x48 image size)\n",
    "TRIGGER_SIZE = 4  # 4x4 block\n",
    "TRIGGER_POS = (\n",
    "    IMG_SIZE - TRIGGER_SIZE - 1,\n",
    "    IMG_SIZE - TRIGGER_SIZE - 1,\n",
    ")  # Bottom-right corner\n",
    "# Trigger Color: Magenta (R=1, G=0, B=1) in [0, 1] range\n",
    "TRIGGER_COLOR_VAL = (1.0, 0.0, 1.0)\n",
    "\n",
    "print(f\"\\nDataset configuration:\")\n",
    "print(f\" Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\" Number of Classes: {NUM_CLASSES_GTSRB}\")\n",
    "print(f\" Source Class: {SOURCE_CLASS} ({get_gtsrb_class_name(SOURCE_CLASS)})\")\n",
    "print(f\" Target Class: {TARGET_CLASS} ({get_gtsrb_class_name(TARGET_CLASS)})\")\n",
    "print(f\" Poison Rate: {POISON_RATE * 100}%\")\n",
    "print(f\" Trigger: {TRIGGER_SIZE}x{TRIGGER_SIZE} magenta square at {TRIGGER_POS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4f56c",
   "metadata": {},
   "source": [
    "## architecure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2172f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTSRB_CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A CNN adapted for the GTSRB dataset (43 classes, 48x48 input).\n",
    "    Implements standard CNN components with adjusted layer dimensions for GTSRB.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=NUM_CLASSES_GTSRB):\n",
    "        \"\"\"\n",
    "        Initializes the CNN layers for GTSRB.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes (default: NUM_CLASSES_GTSRB).\n",
    "        \"\"\"\n",
    "        super(GTSRB_CNN, self).__init__()\n",
    "        # Conv Layer 1: Input 3 channels (RGB), Output 32 filters, Kernel 3x3, Padding 1\n",
    "        # Processes 48x48 input\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        # Output shape: (Batch Size, 32, 48, 48)\n",
    "\n",
    "        # Conv Layer 2: Input 32 channels, Output 64 filters, Kernel 3x3, Padding 1\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, padding=1\n",
    "        )\n",
    "        # Output shape: (Batch Size, 64, 48, 48)\n",
    "\n",
    "        # Max Pooling 1: Kernel 2x2, Stride 2. Reduces spatial dimensions by half.\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Output shape: (Batch Size, 64, 24, 24)\n",
    "\n",
    "        # Conv Layer 3: Input 64 channels, Output 128 filters, Kernel 3x3, Padding 1\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=128, kernel_size=3, padding=1\n",
    "        )\n",
    "        # Output shape: (Batch Size, 128, 24, 24)\n",
    "\n",
    "        # Max Pooling 2: Kernel 2x2, Stride 2. Reduces spatial dimensions by half again.\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Output shape: (Batch Size, 128, 12, 12)\n",
    "\n",
    "        # Calculate flattened feature size after pooling layers\n",
    "        # This is needed for the input size of the first fully connected layer\n",
    "        self._feature_size = 128 * 12 * 12  # 18432\n",
    "\n",
    "        # Fully Connected Layer 1 (Hidden): Maps flattened features to 512 hidden units.\n",
    "        # Input size MUST match self._feature_size\n",
    "        self.fc1 = nn.Linear(self._feature_size, 512)\n",
    "        # Implements Y1 = f(W1 * X_flat + b1), where f is ReLU\n",
    "\n",
    "        # Fully Connected Layer 2 (Output): Maps hidden units to class logits.\n",
    "        # Output size MUST match num_classes\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        # Implements Y_logits = W2 * Y1 + b2\n",
    "\n",
    "        # Dropout layer for regularization (p=0.5 means 50% probability of dropping a unit)\n",
    "        self.dropout = nn.Dropout(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7be3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "\t\"\"\"\n",
    "\tDefines the forward pass sequence for input tensor x.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx (torch.Tensor): Input batch of images\n",
    "\t\t\t\t\t\t\t(Batch Size x 3 x IMG_SIZE x IMG_SIZE).\n",
    "\n",
    "\tReturns:\n",
    "\t\ttorch.Tensor: Output logits for each class\n",
    "\t\t\t\t\t\t\t(Batch Size x num_classes).\n",
    "\t\"\"\"\n",
    "\t# Apply first Conv block: Conv1 -> ReLU -> Conv2 -> ReLU -> Pool1\n",
    "\tx = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
    "\t# Apply second Conv block: Conv3 -> ReLU -> Pool2\n",
    "\tx = self.pool2(F.relu(self.conv3(x)))\n",
    "\n",
    "\t# Flatten the feature map output from the convolutional blocks\n",
    "\tx = x.view(-1, self._feature_size)  # Reshape to (Batch Size, _feature_size)\n",
    "\n",
    "\t# Apply Dropout before the first FC layer (common practice)\n",
    "\tx = self.dropout(x)\n",
    "\t# Apply first FC layer with ReLU activation\n",
    "\tx = F.relu(self.fc1(x))\n",
    "\t# Apply Dropout again before the output layer\n",
    "\tx = self.dropout(x)\n",
    "\t# Apply the final FC layer to get logits\n",
    "\tx = self.fc2(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e66934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN model defined for GTSRB:\n",
      "GTSRB_CNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=18432, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=43, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Calculated feature size before FC layers: 18432\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GTSRB model structure and move it to the configured device\n",
    "model_structure_gtsrb = GTSRB_CNN(num_classes=NUM_CLASSES_GTSRB).to(device)\n",
    "print(\"\\nCNN model defined for GTSRB:\")\n",
    "print(model_structure_gtsrb)\n",
    "print(\n",
    "    f\"Calculated feature size before FC layers: {model_structure_gtsrb._feature_size}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8238ca",
   "metadata": {},
   "source": [
    "## Preparing and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f901b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base transform (Resize + ToTensor) - Applied first to all images\n",
    "transform_base = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Resize to standard size\n",
    "        transforms.ToTensor(),  # Converts PIL Image [0, 255] to Tensor [0, 1]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90a1294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-trigger transform for training data (augmentation + normalization) - Applied last in training\n",
    "transform_train_post = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(10),  # Augmentation: Apply small random rotation\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.2, contrast=0.2\n",
    "        ),  # Augmentation: Adjust color slightly\n",
    "        transforms.Normalize(IMG_MEAN, IMG_STD),  # Normalize using ImageNet stats\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10730877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform for clean test data (Resize, ToTensor, Normalize) - Used for evaluation\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Resize\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "        transforms.Normalize(IMG_MEAN, IMG_STD),  # Normalize\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f913ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform for visualization (reverses normalization)\n",
    "inverse_normalize = transforms.Normalize(\n",
    "    mean=[-m / s for m, s in zip(IMG_MEAN, IMG_STD)], std=[1 / s for s in IMG_STD]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b99dc226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean GTSRB training dataset loaded using ImageFolder. Size: 39209\n",
      "Total 43 classes found by ImageFolder.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load reference training set using ImageFolder to get class-to-index mapping\n",
    "    # This instance won't be used for training directly, only for metadata.\n",
    "    trainset_clean_ref = ImageFolder(root=train_dir)\n",
    "    gtsrb_class_to_idx = (\n",
    "        trainset_clean_ref.class_to_idx\n",
    "    )  # Example: {'00000': 0, '00001': 1, ...} - maps folder names to class indices\n",
    "\n",
    "    # Create the actual clean training dataset using ImageFolder\n",
    "    # For clean training, we apply the full sequence of base + post transforms.\n",
    "    trainset_clean_transformed = ImageFolder(\n",
    "        root=train_dir,\n",
    "        transform=transforms.Compose(\n",
    "            [transform_base, transform_train_post]\n",
    "        ),  # Combine transforms for clean data\n",
    "    )\n",
    "    print(\n",
    "        f\"\\nClean GTSRB training dataset loaded using ImageFolder. Size: {len(trainset_clean_transformed)}\"\n",
    "    )\n",
    "    print(f\"Total {len(trainset_clean_ref.classes)} classes found by ImageFolder.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading GTSRB training data from {train_dir}: {e}\")\n",
    "    print(\n",
    "        \"Please ensure the directory structure is correct for ImageFolder (e.g., GTSRB/Final_Training/Images/00000/*.ppm).\"\n",
    "    )\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a57960fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for clean training data\n",
    "trainloader_clean = DataLoader(\n",
    "    trainset_clean_transformed,\n",
    "    batch_size=256,  # Larger batch size for potentially faster clean training\n",
    "    shuffle=True,  # Shuffle training data each epoch\n",
    "    num_workers=0,  # Set based on system capabilities (0 for simplicity/compatibility)\n",
    "    pin_memory=True,  # Speeds up CPU->GPU transfer if using CUDA\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "152952dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTSRBTestset(Dataset):\n",
    "    \"\"\"Custom Dataset for GTSRB test set using annotations from a CSV file.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset by reading the CSV and storing paths/transforms.\n",
    "\n",
    "        Args:\n",
    "            csv_file (string): Path to the CSV file with 'Filename' and 'ClassId' columns.\n",
    "            img_dir (string): Directory containing the test images.\n",
    "            transform (callable, optional): Transform to be applied to each image.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read the CSV file, ensuring correct delimiter and handling potential BOM\n",
    "            with open(csv_file, mode=\"r\", encoding=\"utf-8-sig\") as f:\n",
    "                self.img_labels = pd.read_csv(f, delimiter=\";\")\n",
    "            # Verify required columns exist\n",
    "            if (\n",
    "                \"Filename\" not in self.img_labels.columns\n",
    "                or \"ClassId\" not in self.img_labels.columns\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    \"CSV file must contain 'Filename' and 'ClassId' columns.\"\n",
    "                )\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Test CSV file not found at '{csv_file}'\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading or parsing GTSRB test CSV '{csv_file}': {e}\")\n",
    "            raise\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        print(\n",
    "            f\"Loaded GTSRB test annotations from CSV '{os.path.basename(csv_file)}'. Found {len(self.img_labels)} entries.\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the test set.\"\"\"\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the image and label for a given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, label) where image is the transformed image tensor,\n",
    "                   and label is the integer class ID. Returns (dummy_tensor, -1)\n",
    "                   if the image file cannot be loaded or processed.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()  # Handle tensor index if needed\n",
    "\n",
    "        try:\n",
    "            # Get image filename and class ID from the pandas DataFrame\n",
    "            img_path_relative = self.img_labels.iloc[idx][\"Filename\"]\n",
    "            img_path = os.path.join(self.img_dir, img_path_relative)\n",
    "            label = int(self.img_labels.iloc[idx][\"ClassId\"])  # Ensure label is integer\n",
    "\n",
    "            # Open image using PIL and ensure it's in RGB format\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Image file not found: {img_path} (Index {idx}). Skipping.\")\n",
    "            return torch.zeros(3, IMG_SIZE, IMG_SIZE), -1\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error opening image {img_path} (Index {idx}): {e}. Skipping.\")\n",
    "            # Return dummy data on other errors as well\n",
    "            return torch.zeros(3, IMG_SIZE, IMG_SIZE), -1\n",
    "\n",
    "        # Apply transforms if they are provided\n",
    "        if self.transform:\n",
    "            try:\n",
    "                image = self.transform(image)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Warning: Error applying transform to image {img_path} (Index {idx}): {e}. Skipping.\"\n",
    "                )\n",
    "                return torch.zeros(3, IMG_SIZE, IMG_SIZE), -1\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f132ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GTSRB test annotations from CSV 'GT-final_test.csv'. Found 12630 entries.\n",
      "Clean GTSRB test dataset loaded. Size: 12630\n"
     ]
    }
   ],
   "source": [
    "# Load Clean Test Data using the custom Dataset\n",
    "try:\n",
    "    testset_clean = GTSRBTestset(\n",
    "        csv_file=test_csv_path,\n",
    "        img_dir=test_img_dir,\n",
    "        transform=transform_test,  # Apply test transforms\n",
    "    )\n",
    "    print(f\"Clean GTSRB test dataset loaded. Size: {len(testset_clean)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating GTSRB test dataset: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0f39e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean GTSRB test dataloader created.\n"
     ]
    }
   ],
   "source": [
    "# Create the DataLoader for the clean test dataset\n",
    "# The DataLoader will now receive samples from GTSRBTestset.__getitem__\n",
    "# We need to be aware that some samples might be (dummy_tensor, -1)\n",
    "# The training/evaluation loops should handle filtering these out if they occur.\n",
    "try:\n",
    "    testloader_clean = DataLoader(\n",
    "        testset_clean,\n",
    "        batch_size=256,  # Batch size for evaluation\n",
    "        shuffle=False,  # No shuffling needed for testing\n",
    "        num_workers=0,  # Set based on system\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    print(f\"Clean GTSRB test dataloader created.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error creating GTSRB test dataloader: {e}\")\n",
    "     raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda08dd",
   "metadata": {},
   "source": [
    "## Attack Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7fe4e",
   "metadata": {},
   "source": [
    "The idea is to apply a trigger function, in our case we are going to overly a small, coloured square pattern in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "942155e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trigger(image_tensor):\n",
    "    \"\"\"\n",
    "    Adds the predefined trigger pattern to a single image tensor.\n",
    "    The input tensor is expected to be in the [0, 1] value range (post ToTensor).\n",
    "\n",
    "    Args:\n",
    "        image_tensor (torch.Tensor): A single image tensor (C x H x W) in [0, 1] range.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The image tensor with the trigger pattern applied.\n",
    "    \"\"\"\n",
    "    # Input tensor shape should be (Channels, Height, Width)\n",
    "    c, h, w = image_tensor.shape\n",
    "\n",
    "    # Check if the input tensor has the expected dimensions\n",
    "    if h != IMG_SIZE or w != IMG_SIZE:\n",
    "        # This might occur if transforms change unexpectedly.\n",
    "        # We print a warning but attempt to proceed.\n",
    "        print(\n",
    "            f\"Warning: add_trigger received tensor of unexpected size {h}x{w}. Expected {IMG_SIZE}x{IMG_SIZE}.\"\n",
    "        )\n",
    "\n",
    "    # Calculate trigger coordinates from predefined constants\n",
    "    start_x, start_y = TRIGGER_POS\n",
    "\n",
    "    # Prepare the trigger color tensor based on input image channels\n",
    "    # Ensure the color tensor has the same number of channels as the image\n",
    "    if c != len(TRIGGER_COLOR_VAL):\n",
    "        # If channel count mismatch (e.g., grayscale input, color trigger), adapt.\n",
    "        print(\n",
    "            f\"Warning: Input tensor channels ({c}) mismatch trigger color channels ({len(TRIGGER_COLOR_VAL)}). Using first color value for all channels.\"\n",
    "        )\n",
    "        # Create a tensor using only the first color value (e.g., R from RGB)\n",
    "        trigger_color_tensor = torch.full(\n",
    "            (c, 1, 1),  # Shape (C, 1, 1) for broadcasting\n",
    "            TRIGGER_COLOR_VAL[0],  # Use the first component of the color tuple\n",
    "            dtype=image_tensor.dtype,\n",
    "            device=image_tensor.device,\n",
    "        )\n",
    "    else:\n",
    "        # Reshape the color tuple (e.g., (1.0, 0.0, 1.0)) into a (C, 1, 1) tensor\n",
    "        trigger_color_tensor = torch.tensor(\n",
    "            TRIGGER_COLOR_VAL, dtype=image_tensor.dtype, device=image_tensor.device\n",
    "        ).view(c, 1, 1)  # Reshape for broadcasting\n",
    "\n",
    "    # Calculate effective trigger boundaries, clamping to image dimensions\n",
    "    # This prevents errors if TRIGGER_POS or TRIGGER_SIZE are invalid\n",
    "    eff_start_y = max(0, min(start_y, h - 1))\n",
    "    eff_start_x = max(0, min(start_x, w - 1))\n",
    "    eff_end_y = max(0, min(start_y + TRIGGER_SIZE, h))\n",
    "    eff_end_x = max(0, min(start_x + TRIGGER_SIZE, w))\n",
    "    eff_trigger_size_y = eff_end_y - eff_start_y\n",
    "    eff_trigger_size_x = eff_end_x - eff_start_x\n",
    "\n",
    "    # Check if the effective trigger size is valid after clamping\n",
    "    if eff_trigger_size_y <= 0 or eff_trigger_size_x <= 0:\n",
    "        print(\n",
    "            f\"Warning: Trigger position {TRIGGER_POS} and size {TRIGGER_SIZE} result in zero effective size on image {h}x{w}. Trigger not applied.\"\n",
    "        )\n",
    "        return image_tensor # Return the original tensor if trigger is effectively size zero\n",
    "\n",
    "    # Apply the trigger by assigning the color tensor to the specified patch\n",
    "    # Broadcasting automatically fills the target area (eff_trigger_size_y x eff_trigger_size_x)\n",
    "    image_tensor[\n",
    "        :,  # All channels\n",
    "        eff_start_y:eff_end_y,  # Y-slice (rows)\n",
    "        eff_start_x:eff_end_x,  # X-slice (columns)\n",
    "    ] = trigger_color_tensor  # Assign the broadcasted color\n",
    "\n",
    "    return image_tensor # Return the modified tensor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
